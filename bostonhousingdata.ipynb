{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request #import urllib works for python 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BOSTON_TRAINING = \"boston_train.csv\"\n",
    "BOSTON_TRAINING_URL = \"http://download.tensorflow.org/data/boston_train.csv\"\n",
    "\n",
    "BOSTON_TEST = \"boston_test.csv\"\n",
    "BOSTON_TEST_URL = \"http://download.tensorflow.org/data/boston_test.csv\"\n",
    "\n",
    "BOSTON_PREDICT = \"boston_predict.csv\"\n",
    "BOSTON_PREDICT_URL = \"http://download.tensorflow.org/data/boston_predict.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BOSTON_TRAINING):\n",
    "  raw = urllib.request.urlopen(BOSTON_TRAINING_URL).read()\n",
    "  with open(BOSTON_TRAINING,'w') as f:\n",
    "    f.write(raw.decode()) \n",
    "\n",
    "if not os.path.exists(BOSTON_TEST):\n",
    "  raw = urllib.request.urlopen(BOSTON_TEST_URL).read()\n",
    "  with open(BOSTON_TEST,'w') as f:\n",
    "    f.write(raw.decode())\n",
    "    \n",
    "if not os.path.exists(BOSTON_PREDICT):\n",
    "  raw = urllib.request.urlopen(BOSTON_PREDICT_URL).read()\n",
    "  with open(BOSTON_PREDICT,'w') as f:\n",
    "    f.write(raw.decode())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "            \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\"\n",
    "\n",
    "training_set = pd.read_csv(\"boston_train.csv\", skipinitialspace=True,\n",
    "                           skiprows=1, names=COLUMNS)\n",
    "test_set = pd.read_csv(\"boston_test.csv\", skipinitialspace=True,\n",
    "                       skiprows=1, names=COLUMNS)\n",
    "prediction_set = pd.read_csv(\"boston_predict.csv\", skipinitialspace=True,\n",
    "                             skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [tf.contrib.layers.real_valued_column(k)\n",
    "                  for k in FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11fec7780>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols,\n",
    "                                          hidden_units=[10, 10],\n",
    "                                          model_dir=\"/tmp/boston_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(data_set):\n",
    "  feature_cols = {k: tf.constant(data_set[k].values)\n",
    "                  for k in FEATURES}\n",
    "  labels = tf.constant(data_set[LABEL].values)\n",
    "  return feature_cols, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/mac/anaconda3/envs/uppingtensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/boston_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 293.651, step = 1\n",
      "INFO:tensorflow:global_step/sec: 763.703\n",
      "INFO:tensorflow:loss = 92.4398, step = 101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 709.039\n",
      "INFO:tensorflow:loss = 82.5393, step = 201 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 825.431\n",
      "INFO:tensorflow:loss = 77.4206, step = 301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.819\n",
      "INFO:tensorflow:loss = 73.5605, step = 401 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.997\n",
      "INFO:tensorflow:loss = 70.9561, step = 501 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 738.548\n",
      "INFO:tensorflow:loss = 68.1751, step = 601 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 804.854\n",
      "INFO:tensorflow:loss = 66.0562, step = 701 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.079\n",
      "INFO:tensorflow:loss = 63.4605, step = 801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.654\n",
      "INFO:tensorflow:loss = 60.7622, step = 901 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.912\n",
      "INFO:tensorflow:loss = 58.0513, step = 1001 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 727.325\n",
      "INFO:tensorflow:loss = 55.7892, step = 1101 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 778.332\n",
      "INFO:tensorflow:loss = 53.5212, step = 1201 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.09\n",
      "INFO:tensorflow:loss = 50.9295, step = 1301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.622\n",
      "INFO:tensorflow:loss = 47.9448, step = 1401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.422\n",
      "INFO:tensorflow:loss = 46.5147, step = 1501 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.349\n",
      "INFO:tensorflow:loss = 44.9188, step = 1601 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.429\n",
      "INFO:tensorflow:loss = 42.9877, step = 1701 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.469\n",
      "INFO:tensorflow:loss = 41.6045, step = 1801 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.208\n",
      "INFO:tensorflow:loss = 40.5178, step = 1901 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.776\n",
      "INFO:tensorflow:loss = 38.1705, step = 2001 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.109\n",
      "INFO:tensorflow:loss = 36.1656, step = 2101 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.443\n",
      "INFO:tensorflow:loss = 36.9786, step = 2201 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.126\n",
      "INFO:tensorflow:loss = 36.5906, step = 2301 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.651\n",
      "INFO:tensorflow:loss = 35.3336, step = 2401 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 780.177\n",
      "INFO:tensorflow:loss = 34.0184, step = 2501 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 677.425\n",
      "INFO:tensorflow:loss = 32.7901, step = 2601 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.416\n",
      "INFO:tensorflow:loss = 33.951, step = 2701 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.327\n",
      "INFO:tensorflow:loss = 31.6479, step = 2801 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.907\n",
      "INFO:tensorflow:loss = 32.6129, step = 2901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.884\n",
      "INFO:tensorflow:loss = 30.5153, step = 3001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.684\n",
      "INFO:tensorflow:loss = 30.14, step = 3101 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 790.932\n",
      "INFO:tensorflow:loss = 29.8443, step = 3201 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 777.776\n",
      "INFO:tensorflow:loss = 29.9478, step = 3301 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 743.505\n",
      "INFO:tensorflow:loss = 29.3875, step = 3401 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.687\n",
      "INFO:tensorflow:loss = 29.1869, step = 3501 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.066\n",
      "INFO:tensorflow:loss = 28.9745, step = 3601 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.784\n",
      "INFO:tensorflow:loss = 28.7885, step = 3701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.256\n",
      "INFO:tensorflow:loss = 29.815, step = 3801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.124\n",
      "INFO:tensorflow:loss = 28.808, step = 3901 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.355\n",
      "INFO:tensorflow:loss = 28.7605, step = 4001 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.94\n",
      "INFO:tensorflow:loss = 28.3884, step = 4101 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.726\n",
      "INFO:tensorflow:loss = 28.1752, step = 4201 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 866.756\n",
      "INFO:tensorflow:loss = 28.0243, step = 4301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.783\n",
      "INFO:tensorflow:loss = 28.3604, step = 4401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 777.356\n",
      "INFO:tensorflow:loss = 28.1602, step = 4501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.503\n",
      "INFO:tensorflow:loss = 27.824, step = 4601 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 778.979\n",
      "INFO:tensorflow:loss = 27.6419, step = 4701 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.002\n",
      "INFO:tensorflow:loss = 27.7446, step = 4801 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.561\n",
      "INFO:tensorflow:loss = 27.7738, step = 4901 (0.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/boston_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 27.4245.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x10e24cd68>, 'hidden_units': [10, 10], 'feature_columns': (_RealValuedColumn(column_name='crim', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='zn', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='indus', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='nox', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='rm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dis', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='tax', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='ptratio', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)), 'optimizer': None, 'activation_fn': <function relu at 0x11c902d90>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/mac/anaconda3/envs/uppingtensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-03-19:33:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boston_model/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-03-19:33:39\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 12.1565\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "ev = regressor.evaluate(input_fn=lambda: input_fn(test_set), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 12.156476\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/envs/uppingtensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:335: calling DNNRegressor.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_scores, or set `outputs` argument.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boston_model/model.ckpt-5000\n",
      "Predictions: [34.596008, 19.897644, 22.6633, 36.555283, 14.575801, 18.593182]\n"
     ]
    }
   ],
   "source": [
    "y = regressor.predict(input_fn=lambda: input_fn(prediction_set))\n",
    "# .predict() returns an iterator; convert to a list and print predictions\n",
    "predictions = list(itertools.islice(y, 6))\n",
    "print (\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
